{"metadata":{"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30698,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"papermill":{"default_parameters":{},"duration":48.434265,"end_time":"2024-04-05T14:47:25.841756","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2024-04-05T14:46:37.407491","version":"2.5.0"},"widgets":{"application/vnd.jupyter.widget-state+json":{"state":{"01c349150a544211bdaf52fe121be901":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8603016bc8ec4421995e41bdb1206578","placeholder":"​","style":"IPY_MODEL_272174f11d8c4a2f99e1122103e8a25c","value":"tokenizer_config.json: 100%"}},"0ea745decfc748b0bd6dc077def6fb7d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"17873f1d933f4d7bae4b019cd4aa95b0":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2660f345087040f69f8d36d566115ca1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d6d144057fe5441fbd1e862187162190","placeholder":"​","style":"IPY_MODEL_d9edbf54860548828a006e094fbd2d83","value":" 232k/232k [00:00&lt;00:00, 3.32MB/s]"}},"272174f11d8c4a2f99e1122103e8a25c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"275fe2ef54974f4ab43f78f62996af5f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2834084ae9b44440bf81647af3b40217":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9797878f7a5341c4b4d0693a2b4ed5c0","placeholder":"​","style":"IPY_MODEL_9a20130218554433a082c0274e968b42","value":"vocab.txt: 100%"}},"298c18db4979473e8de04837b65a8f0e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2d007a0808c040c998f1a75e7280e91f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"314b505f9ecb44149c57168305f36f53":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3493055252d24c31a8aee11f9582c171":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8941e43585314970b466bc95eb96b2c2","max":231508,"min":0,"orientation":"horizontal","style":"IPY_MODEL_298c18db4979473e8de04837b65a8f0e","value":231508}},"36aea6ea9ec843d6bdc37d493e87fa89":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_72f8f46df0ca42b0bd7872978e980a9c","IPY_MODEL_a404f18033c44f369a316f6f1a3d48d9","IPY_MODEL_d0207259d9e842dda8c33fd933176c24"],"layout":"IPY_MODEL_275fe2ef54974f4ab43f78f62996af5f"}},"38b959a9f6a3432c9f2722a3b4120f8b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3edfd96e73ed46f78d7349b55c1cc238":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b185ceefa2cc4211aec525e95e9e1697","placeholder":"​","style":"IPY_MODEL_0ea745decfc748b0bd6dc077def6fb7d","value":"model.safetensors: 100%"}},"4752b44cae144652bf60063c7cbe5632":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_01c349150a544211bdaf52fe121be901","IPY_MODEL_c25ab841bdc44f879bca11f5fb03556d","IPY_MODEL_753f2e3870574cd5af268f9e420bd0bf"],"layout":"IPY_MODEL_837e4b369db24034b08e65e0a9defe9d"}},"4aa85d953e804a829f0014011723e8c6":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6b11726f2aa64bcfb20c606bd6c8146a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_38b959a9f6a3432c9f2722a3b4120f8b","placeholder":"​","style":"IPY_MODEL_b386387b70a84b1b815e09eaa5c72030","value":" 268M/268M [00:01&lt;00:00, 187MB/s]"}},"72f8f46df0ca42b0bd7872978e980a9c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f2cf8e9f102a46099f53513f2711a346","placeholder":"​","style":"IPY_MODEL_fdf11266b48b4a158059ddc7cde62682","value":"config.json: 100%"}},"753f2e3870574cd5af268f9e420bd0bf":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2d007a0808c040c998f1a75e7280e91f","placeholder":"​","style":"IPY_MODEL_dfc934c617274e278d9ebe05a76e3d08","value":" 48.0/48.0 [00:00&lt;00:00, 2.58kB/s]"}},"7647fbb531d24a4bbd6bbc9635d873a1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3edfd96e73ed46f78d7349b55c1cc238","IPY_MODEL_d2c319f9f9824a8388570bb27a41eb2f","IPY_MODEL_6b11726f2aa64bcfb20c606bd6c8146a"],"layout":"IPY_MODEL_f3726584f834425a865b96ae6ecc8b0b"}},"837e4b369db24034b08e65e0a9defe9d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8603016bc8ec4421995e41bdb1206578":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"869b17ec1fa344e6bfe9d45461d63c1b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8941e43585314970b466bc95eb96b2c2":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9797878f7a5341c4b4d0693a2b4ed5c0":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9a20130218554433a082c0274e968b42":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a404f18033c44f369a316f6f1a3d48d9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_17873f1d933f4d7bae4b019cd4aa95b0","max":629,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ae558ddd72634a298a30adb895534e24","value":629}},"ae558ddd72634a298a30adb895534e24":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b170e7b32fe6447dbdf7461a39cc406d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b185ceefa2cc4211aec525e95e9e1697":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b386387b70a84b1b815e09eaa5c72030":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c25ab841bdc44f879bca11f5fb03556d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_314b505f9ecb44149c57168305f36f53","max":48,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b170e7b32fe6447dbdf7461a39cc406d","value":48}},"c2daede3c50b4817be3572a2bc0d7663":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d0207259d9e842dda8c33fd933176c24":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4aa85d953e804a829f0014011723e8c6","placeholder":"​","style":"IPY_MODEL_869b17ec1fa344e6bfe9d45461d63c1b","value":" 629/629 [00:00&lt;00:00, 30.2kB/s]"}},"d0960f124f0e42f7b7f673e34126761f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2834084ae9b44440bf81647af3b40217","IPY_MODEL_3493055252d24c31a8aee11f9582c171","IPY_MODEL_2660f345087040f69f8d36d566115ca1"],"layout":"IPY_MODEL_e45ccb8142d14aa3aef1f5fbf47829cc"}},"d2c319f9f9824a8388570bb27a41eb2f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e0f0482500034261848f35cb334c5fc1","max":267832558,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c2daede3c50b4817be3572a2bc0d7663","value":267832558}},"d6d144057fe5441fbd1e862187162190":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d9edbf54860548828a006e094fbd2d83":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"dfc934c617274e278d9ebe05a76e3d08":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e0f0482500034261848f35cb334c5fc1":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e45ccb8142d14aa3aef1f5fbf47829cc":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f2cf8e9f102a46099f53513f2711a346":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f3726584f834425a865b96ae6ecc8b0b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fdf11266b48b4a158059ddc7cde62682":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}},"version_major":2,"version_minor":0}}},"nbformat_minor":5,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# 1. Utilisation des Transformers de Hugging Face 🤗","metadata":{"papermill":{"duration":0.00618,"end_time":"2024-04-05T14:46:41.264293","exception":false,"start_time":"2024-04-05T14:46:41.258113","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# commencez par installer la bibliothèque transformers si vous n'utilisez pas Colab ou Kaggle\n\n!pip install transformers","metadata":{"execution":{"iopub.status.busy":"2024-05-26T16:50:17.057938Z","iopub.execute_input":"2024-05-26T16:50:17.058348Z","iopub.status.idle":"2024-05-26T16:50:29.846663Z","shell.execute_reply.started":"2024-05-26T16:50:17.058317Z","shell.execute_reply":"2024-05-26T16:50:29.845559Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.39.3)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.13.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.22.2)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.12.25)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.31.0)\nRequirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.15.2)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.3)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2024.2.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.2.2)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Preprocessing avec un Tokenizer","metadata":{"papermill":{"duration":0.005112,"end_time":"2024-04-05T14:46:41.275532","exception":false,"start_time":"2024-04-05T14:46:41.270420","status":"completed"},"tags":[]}},{"cell_type":"code","source":"from transformers import AutoTokenizer    \n\ncheckpoint = \"distilbert-base-uncased-finetuned-sst-2-english\"\ntokenizer = AutoTokenizer.from_pretrained(checkpoint)","metadata":{"papermill":{"duration":10.542038,"end_time":"2024-04-05T14:46:51.822881","exception":false,"start_time":"2024-04-05T14:46:41.280843","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-05-26T16:54:58.896381Z","iopub.execute_input":"2024-05-26T16:54:58.896815Z","iopub.status.idle":"2024-05-26T16:54:59.130407Z","shell.execute_reply.started":"2024-05-26T16:54:58.896783Z","shell.execute_reply":"2024-05-26T16:54:59.129240Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"raw_inputs = [\n    \"Burkina Faso is a West African country divided into 45 provinces.\",\n    \"The official language is French, but other national languages such as Mooré, Peul, Dioula and Bissa are also spoken.\",\n]\n\ninputs = tokenizer(raw_inputs, padding=True, truncation=True, return_tensors=\"tf\")\nprint(inputs)","metadata":{"papermill":{"duration":19.194406,"end_time":"2024-04-05T14:47:11.025015","exception":false,"start_time":"2024-04-05T14:46:51.830609","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-05-26T16:55:09.424493Z","iopub.execute_input":"2024-05-26T16:55:09.425458Z","iopub.status.idle":"2024-05-26T16:55:09.433612Z","shell.execute_reply.started":"2024-05-26T16:55:09.425423Z","shell.execute_reply":"2024-05-26T16:55:09.432621Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stdout","text":"{'input_ids': <tf.Tensor: shape=(2, 29), dtype=int32, numpy=\narray([[  101, 23089, 22773,  2003,  1037,  2225,  3060,  2406,  4055,\n         2046,  3429,  6941,  1012,   102,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0],\n       [  101,  1996,  2880,  2653,  2003,  2413,  1010,  2021,  2060,\n         2120,  4155,  2107,  2004,  5405,  1010, 21877,  5313,  1010,\n         4487,  7140,  2721,  1998, 20377,  3736,  2024,  2036,  5287,\n         1012,   102]], dtype=int32)>, 'attention_mask': <tf.Tensor: shape=(2, 29), dtype=int32, numpy=\narray([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0],\n       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1]], dtype=int32)>}\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Passer le modèle en revue","metadata":{"papermill":{"duration":0.009441,"end_time":"2024-04-05T14:47:11.045254","exception":false,"start_time":"2024-04-05T14:47:11.035813","status":"completed"},"tags":[]}},{"cell_type":"code","source":"from transformers import TFAutoModel\n\ncheckpoint = \"distilbert-base-uncased-finetuned-sst-2-english\"\nmodel = TFAutoModel.from_pretrained(checkpoint)","metadata":{"papermill":{"duration":7.579935,"end_time":"2024-04-05T14:47:18.632869","exception":false,"start_time":"2024-04-05T14:47:11.052934","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-05-26T16:55:15.890154Z","iopub.execute_input":"2024-05-26T16:55:15.890529Z","iopub.status.idle":"2024-05-26T16:55:17.603090Z","shell.execute_reply.started":"2024-05-26T16:55:15.890499Z","shell.execute_reply":"2024-05-26T16:55:17.602094Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stderr","text":"Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFDistilBertModel: ['pre_classifier.weight', 'classifier.bias', 'pre_classifier.bias', 'classifier.weight']\n- This IS expected if you are initializing TFDistilBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing TFDistilBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\nAll the weights of TFDistilBertModel were initialized from the PyTorch model.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertModel for predictions without further training.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Vecteur de grande dimension (High-dimensional vector) ?","metadata":{"papermill":{"duration":0.006687,"end_time":"2024-04-05T14:47:18.646787","exception":false,"start_time":"2024-04-05T14:47:18.640100","status":"completed"},"tags":[]}},{"cell_type":"code","source":"outputs = model(inputs)\nprint(outputs.last_hidden_state.shape)","metadata":{"papermill":{"duration":0.495429,"end_time":"2024-04-05T14:47:19.148862","exception":false,"start_time":"2024-04-05T14:47:18.653433","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-05-26T16:55:41.857815Z","iopub.execute_input":"2024-05-26T16:55:41.858651Z","iopub.status.idle":"2024-05-26T16:55:42.058683Z","shell.execute_reply.started":"2024-05-26T16:55:41.858613Z","shell.execute_reply":"2024-05-26T16:55:42.057598Z"},"trusted":true},"execution_count":33,"outputs":[{"name":"stdout","text":"(2, 29, 768)\n","output_type":"stream"}]},{"cell_type":"code","source":"outputs[0]","metadata":{"papermill":{"duration":0.023537,"end_time":"2024-04-05T14:47:19.180610","exception":false,"start_time":"2024-04-05T14:47:19.157073","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-05-26T16:55:42.967115Z","iopub.execute_input":"2024-05-26T16:55:42.967759Z","iopub.status.idle":"2024-05-26T16:55:42.975604Z","shell.execute_reply.started":"2024-05-26T16:55:42.967728Z","shell.execute_reply":"2024-05-26T16:55:42.974554Z"},"trusted":true},"execution_count":34,"outputs":[{"execution_count":34,"output_type":"execute_result","data":{"text/plain":"<tf.Tensor: shape=(2, 29, 768), dtype=float32, numpy=\narray([[[-0.18444543,  0.18406054, -0.3317901 , ..., -0.33912918,\n          0.6345618 , -0.21481766],\n        [ 0.5576094 ,  0.5374135 , -0.26444602, ..., -0.6617011 ,\n          0.73083746, -0.58173436],\n        [ 0.33717203,  0.7582899 , -0.15661317, ..., -0.8102957 ,\n          0.37502262, -0.1652882 ],\n        ...,\n        [-0.22423077,  0.4882026 , -0.7373865 , ..., -0.35429463,\n          0.28613007, -0.8663359 ],\n        [ 0.16610484,  0.35079545, -0.37180883, ..., -0.44478616,\n          0.29429734, -0.6339572 ],\n        [-0.1446706 ,  0.31071886, -0.62418133, ..., -0.31383926,\n          0.15263262, -0.43699735]],\n\n       [[ 0.20606035,  0.767488  , -0.36321968, ..., -0.25143635,\n          0.46576267, -0.49673885],\n        [-0.22202978,  0.4234435 , -0.4924144 , ..., -0.00735636,\n          0.8536247 ,  0.3430001 ],\n        [-0.41844034,  0.65331614, -0.05087002, ..., -0.33773685,\n          0.93199396,  0.47552633],\n        ...,\n        [ 0.41537088,  1.1392596 , -0.03990367, ..., -0.07835131,\n          0.30962306, -0.7232689 ],\n        [ 0.9223254 ,  0.0381694 , -0.08765277, ...,  0.74142706,\n         -0.24472395, -0.29223117],\n        [ 0.16238059,  0.52012324, -0.52342016, ...,  0.3963744 ,\n          0.5045525 , -0.2511695 ]]], dtype=float32)>"},"metadata":{}}]},{"cell_type":"markdown","source":"### Têtes de modèle (Heads) : Donner du sens aux chiffres","metadata":{"papermill":{"duration":0.007031,"end_time":"2024-04-05T14:47:19.194931","exception":false,"start_time":"2024-04-05T14:47:19.187900","status":"completed"},"tags":[]}},{"cell_type":"code","source":"from transformers import TFAutoModelForSequenceClassification  # ajout d'une tete pour la classification de séquences\n\ncheckpoint = \"distilbert-base-uncased-finetuned-sst-2-english\"\nmodel = TFAutoModelForSequenceClassification.from_pretrained(checkpoint)\noutputs = model(inputs)","metadata":{"papermill":{"duration":2.879514,"end_time":"2024-04-05T14:47:22.082790","exception":false,"start_time":"2024-04-05T14:47:19.203276","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-05-26T16:55:45.788283Z","iopub.execute_input":"2024-05-26T16:55:45.788677Z","iopub.status.idle":"2024-05-26T16:55:47.637190Z","shell.execute_reply.started":"2024-05-26T16:55:45.788646Z","shell.execute_reply":"2024-05-26T16:55:47.636139Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stderr","text":"All PyTorch model weights were used when initializing TFDistilBertForSequenceClassification.\n\nAll the weights of TFDistilBertForSequenceClassification were initialized from the PyTorch model.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertForSequenceClassification for predictions without further training.\n","output_type":"stream"}]},{"cell_type":"code","source":"outputs.logits.shape","metadata":{"papermill":{"duration":0.023521,"end_time":"2024-04-05T14:47:22.116336","exception":false,"start_time":"2024-04-05T14:47:22.092815","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-05-26T16:55:47.639030Z","iopub.execute_input":"2024-05-26T16:55:47.639412Z","iopub.status.idle":"2024-05-26T16:55:47.646130Z","shell.execute_reply.started":"2024-05-26T16:55:47.639379Z","shell.execute_reply":"2024-05-26T16:55:47.645063Z"},"trusted":true},"execution_count":36,"outputs":[{"execution_count":36,"output_type":"execute_result","data":{"text/plain":"TensorShape([2, 2])"},"metadata":{}}]},{"cell_type":"markdown","source":"### Postprocessing outputs","metadata":{"papermill":{"duration":0.007355,"end_time":"2024-04-05T14:47:22.132669","exception":false,"start_time":"2024-04-05T14:47:22.125314","status":"completed"},"tags":[]}},{"cell_type":"code","source":"print(outputs.logits)","metadata":{"papermill":{"duration":0.021204,"end_time":"2024-04-05T14:47:22.162672","exception":false,"start_time":"2024-04-05T14:47:22.141468","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-05-26T16:55:57.730412Z","iopub.execute_input":"2024-05-26T16:55:57.730794Z","iopub.status.idle":"2024-05-26T16:55:57.736188Z","shell.execute_reply.started":"2024-05-26T16:55:57.730765Z","shell.execute_reply":"2024-05-26T16:55:57.735027Z"},"trusted":true},"execution_count":38,"outputs":[{"name":"stdout","text":"tf.Tensor(\n[[-1.6803675  1.6408637]\n [-1.7621164  1.7131441]], shape=(2, 2), dtype=float32)\n","output_type":"stream"}]},{"cell_type":"code","source":"import tensorflow as tf\n\npredictions = tf.math.softmax(outputs.logits, axis=-1)\nprint(predictions)","metadata":{"papermill":{"duration":0.022275,"end_time":"2024-04-05T14:47:22.193204","exception":false,"start_time":"2024-04-05T14:47:22.170929","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-05-26T16:55:57.907797Z","iopub.execute_input":"2024-05-26T16:55:57.908181Z","iopub.status.idle":"2024-05-26T16:55:57.915103Z","shell.execute_reply.started":"2024-05-26T16:55:57.908155Z","shell.execute_reply":"2024-05-26T16:55:57.913914Z"},"trusted":true},"execution_count":39,"outputs":[{"name":"stdout","text":"tf.Tensor(\n[[0.03484998 0.96515   ]\n [0.0300244  0.9699756 ]], shape=(2, 2), dtype=float32)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# 2. Les Modèles sur 🤗","metadata":{}},{"cell_type":"markdown","source":"## Creation d'un Transformer: le cas de BERT","metadata":{}},{"cell_type":"code","source":"from transformers import BertConfig, TFBertModel\n\n# the config\nconfig = BertConfig()\n\n# the model from the config\nmodel = TFBertModel(config)","metadata":{"execution":{"iopub.status.busy":"2024-05-26T16:56:15.955887Z","iopub.execute_input":"2024-05-26T16:56:15.956246Z","iopub.status.idle":"2024-05-26T16:56:16.119728Z","shell.execute_reply.started":"2024-05-26T16:56:15.956222Z","shell.execute_reply":"2024-05-26T16:56:16.118632Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"print(config)","metadata":{"execution":{"iopub.status.busy":"2024-05-26T16:56:16.958845Z","iopub.execute_input":"2024-05-26T16:56:16.959765Z","iopub.status.idle":"2024-05-26T16:56:16.965562Z","shell.execute_reply.started":"2024-05-26T16:56:16.959729Z","shell.execute_reply":"2024-05-26T16:56:16.964478Z"},"trusted":true},"execution_count":41,"outputs":[{"name":"stdout","text":"BertConfig {\n  \"attention_probs_dropout_prob\": 0.1,\n  \"classifier_dropout\": null,\n  \"hidden_act\": \"gelu\",\n  \"hidden_dropout_prob\": 0.1,\n  \"hidden_size\": 768,\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 3072,\n  \"layer_norm_eps\": 1e-12,\n  \"max_position_embeddings\": 512,\n  \"model_type\": \"bert\",\n  \"num_attention_heads\": 12,\n  \"num_hidden_layers\": 12,\n  \"pad_token_id\": 0,\n  \"position_embedding_type\": \"absolute\",\n  \"transformers_version\": \"4.39.3\",\n  \"type_vocab_size\": 2,\n  \"use_cache\": true,\n  \"vocab_size\": 30522\n}\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Méthodes de chargement des modèles","metadata":{}},{"cell_type":"code","source":"from transformers import BertConfig, TFBertModel\n\nconfig = BertConfig()\nmodel = TFBertModel(config)\n\n# Ici les paramètres du modèle seront initialisés aléatoirement","metadata":{"execution":{"iopub.status.busy":"2024-05-26T16:56:41.591137Z","iopub.execute_input":"2024-05-26T16:56:41.591549Z","iopub.status.idle":"2024-05-26T16:56:41.747871Z","shell.execute_reply.started":"2024-05-26T16:56:41.591520Z","shell.execute_reply":"2024-05-26T16:56:41.746820Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"from transformers import TFBertModel\n\n# ici on charge le modèle de base de BERT prétrainé\nmodel = TFBertModel.from_pretrained(\"bert-base-cased\")","metadata":{"execution":{"iopub.status.busy":"2024-05-26T16:57:14.423029Z","iopub.execute_input":"2024-05-26T16:57:14.423873Z","iopub.status.idle":"2024-05-26T16:57:17.024460Z","shell.execute_reply.started":"2024-05-26T16:57:14.423819Z","shell.execute_reply":"2024-05-26T16:57:17.023396Z"},"trusted":true},"execution_count":43,"outputs":[{"name":"stderr","text":"Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight']\n- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\nAll the weights of TFBertModel were initialized from the PyTorch model.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Enregistrer avec la méthode \"save_pretrained\"","metadata":{}},{"cell_type":"code","source":"model.save_pretrained(\"mon_repertoire\")","metadata":{"execution":{"iopub.status.busy":"2024-05-26T16:59:17.462032Z","iopub.execute_input":"2024-05-26T16:59:17.462400Z","iopub.status.idle":"2024-05-26T16:59:18.520713Z","shell.execute_reply.started":"2024-05-26T16:59:17.462373Z","shell.execute_reply":"2024-05-26T16:59:18.519603Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"# ls affiche tout simplement le contenu du répertoire mon_repertoire\n\n!ls mon_repertoire","metadata":{"execution":{"iopub.status.busy":"2024-05-26T17:00:32.000772Z","iopub.execute_input":"2024-05-26T17:00:32.001190Z","iopub.status.idle":"2024-05-26T17:00:33.062919Z","shell.execute_reply.started":"2024-05-26T17:00:32.001161Z","shell.execute_reply":"2024-05-26T17:00:33.061550Z"},"trusted":true},"execution_count":52,"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"config.json  tf_model.h5\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# 3. Les Tokenizers sur 🤗","metadata":{}},{"cell_type":"markdown","source":"## Loading and saving","metadata":{}},{"cell_type":"code","source":"from transformers import BertTokenizer\n\ntokenizer = BertTokenizer.from_pretrained(\"bert-base-cased\")","metadata":{"execution":{"iopub.status.busy":"2024-05-26T17:02:14.924510Z","iopub.execute_input":"2024-05-26T17:02:14.924986Z","iopub.status.idle":"2024-05-26T17:02:15.168413Z","shell.execute_reply.started":"2024-05-26T17:02:14.924950Z","shell.execute_reply":"2024-05-26T17:02:15.167326Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoTokenizer\n\ntokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")","metadata":{"execution":{"iopub.status.busy":"2024-05-26T17:02:16.005465Z","iopub.execute_input":"2024-05-26T17:02:16.005865Z","iopub.status.idle":"2024-05-26T17:02:16.159116Z","shell.execute_reply.started":"2024-05-26T17:02:16.005809Z","shell.execute_reply":"2024-05-26T17:02:16.158138Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"code","source":"tokenizer(\"Using a Transformer network is simple\")","metadata":{"execution":{"iopub.status.busy":"2024-05-26T17:02:17.033905Z","iopub.execute_input":"2024-05-26T17:02:17.034274Z","iopub.status.idle":"2024-05-26T17:02:17.042043Z","shell.execute_reply.started":"2024-05-26T17:02:17.034247Z","shell.execute_reply":"2024-05-26T17:02:17.040906Z"},"trusted":true},"execution_count":55,"outputs":[{"execution_count":55,"output_type":"execute_result","data":{"text/plain":"{'input_ids': [101, 7993, 170, 13809, 23763, 2443, 1110, 3014, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1]}"},"metadata":{}}]},{"cell_type":"code","source":"tokenizer.save_pretrained(\"directory_on_my_computer\")\n","metadata":{"execution":{"iopub.status.busy":"2024-05-26T17:02:17.900794Z","iopub.execute_input":"2024-05-26T17:02:17.901799Z","iopub.status.idle":"2024-05-26T17:02:17.928956Z","shell.execute_reply.started":"2024-05-26T17:02:17.901761Z","shell.execute_reply":"2024-05-26T17:02:17.927872Z"},"trusted":true},"execution_count":56,"outputs":[{"execution_count":56,"output_type":"execute_result","data":{"text/plain":"('directory_on_my_computer/tokenizer_config.json',\n 'directory_on_my_computer/special_tokens_map.json',\n 'directory_on_my_computer/vocab.txt',\n 'directory_on_my_computer/added_tokens.json',\n 'directory_on_my_computer/tokenizer.json')"},"metadata":{}}]},{"cell_type":"markdown","source":"### Tokenization","metadata":{}},{"cell_type":"code","source":"from transformers import AutoTokenizer\n\ntokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n\nsequence = \"Using a Transformer network is simple\"\ntokens = tokenizer.tokenize(sequence)\n\nprint(tokens)","metadata":{"execution":{"iopub.status.busy":"2024-05-26T17:02:21.193298Z","iopub.execute_input":"2024-05-26T17:02:21.193694Z","iopub.status.idle":"2024-05-26T17:02:21.351002Z","shell.execute_reply.started":"2024-05-26T17:02:21.193663Z","shell.execute_reply":"2024-05-26T17:02:21.349929Z"},"trusted":true},"execution_count":57,"outputs":[{"name":"stdout","text":"['Using', 'a', 'Trans', '##former', 'network', 'is', 'simple']\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### From tokens to input IDs","metadata":{"execution":{"iopub.status.busy":"2024-05-26T16:48:25.872339Z","iopub.execute_input":"2024-05-26T16:48:25.873307Z","iopub.status.idle":"2024-05-26T16:48:25.877524Z","shell.execute_reply.started":"2024-05-26T16:48:25.873271Z","shell.execute_reply":"2024-05-26T16:48:25.876363Z"}}},{"cell_type":"code","source":"ids = tokenizer.convert_tokens_to_ids(tokens)\n\nprint(ids)","metadata":{"execution":{"iopub.status.busy":"2024-05-26T17:02:21.498092Z","iopub.execute_input":"2024-05-26T17:02:21.498479Z","iopub.status.idle":"2024-05-26T17:02:21.503820Z","shell.execute_reply.started":"2024-05-26T17:02:21.498451Z","shell.execute_reply":"2024-05-26T17:02:21.502588Z"},"trusted":true},"execution_count":58,"outputs":[{"name":"stdout","text":"[7993, 170, 13809, 23763, 2443, 1110, 3014]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Decoding","metadata":{}},{"cell_type":"code","source":"decoded_string = tokenizer.decode([7993, 170, 11303, 1200, 2443, 1110, 3014])\n\nprint(decoded_string)","metadata":{"execution":{"iopub.status.busy":"2024-05-26T17:02:24.696284Z","iopub.execute_input":"2024-05-26T17:02:24.696645Z","iopub.status.idle":"2024-05-26T17:02:24.703264Z","shell.execute_reply.started":"2024-05-26T17:02:24.696618Z","shell.execute_reply":"2024-05-26T17:02:24.702051Z"},"trusted":true},"execution_count":59,"outputs":[{"name":"stdout","text":"Using a transformer network is simple\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# 4. Gestion des séquences multiples 🤗","metadata":{}},{"cell_type":"markdown","source":"## Les modèles attendent un batch (lot) d'entrées par défaut","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nfrom transformers import AutoTokenizer, TFAutoModelForSequenceClassification\n\ncheckpoint = \"distilbert-base-uncased-finetuned-sst-2-english\"\ntokenizer = AutoTokenizer.from_pretrained(checkpoint)\nmodel = TFAutoModelForSequenceClassification.from_pretrained(checkpoint)\n\nsequence = \"I've been waiting for a HuggingFace course my whole life.\"\n\ntokens = tokenizer.tokenize(sequence)\nids = tokenizer.convert_tokens_to_ids(tokens)\ninput_ids = tf.constant(ids)","metadata":{"execution":{"iopub.status.busy":"2024-05-26T17:03:45.703626Z","iopub.execute_input":"2024-05-26T17:03:45.704071Z","iopub.status.idle":"2024-05-26T17:03:47.701777Z","shell.execute_reply.started":"2024-05-26T17:03:45.704040Z","shell.execute_reply":"2024-05-26T17:03:47.700707Z"},"trusted":true},"execution_count":60,"outputs":[{"name":"stderr","text":"All PyTorch model weights were used when initializing TFDistilBertForSequenceClassification.\n\nAll the weights of TFDistilBertForSequenceClassification were initialized from the PyTorch model.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertForSequenceClassification for predictions without further training.\n","output_type":"stream"}]},{"cell_type":"code","source":"ids","metadata":{"execution":{"iopub.status.busy":"2024-05-26T17:03:47.703442Z","iopub.execute_input":"2024-05-26T17:03:47.703761Z","iopub.status.idle":"2024-05-26T17:03:47.710194Z","shell.execute_reply.started":"2024-05-26T17:03:47.703734Z","shell.execute_reply":"2024-05-26T17:03:47.709177Z"},"trusted":true},"execution_count":61,"outputs":[{"execution_count":61,"output_type":"execute_result","data":{"text/plain":"[1045,\n 1005,\n 2310,\n 2042,\n 3403,\n 2005,\n 1037,\n 17662,\n 12172,\n 2607,\n 2026,\n 2878,\n 2166,\n 1012]"},"metadata":{}}]},{"cell_type":"code","source":"input_ids","metadata":{"execution":{"iopub.status.busy":"2024-05-26T17:03:48.755981Z","iopub.execute_input":"2024-05-26T17:03:48.756376Z","iopub.status.idle":"2024-05-26T17:03:48.763750Z","shell.execute_reply.started":"2024-05-26T17:03:48.756346Z","shell.execute_reply":"2024-05-26T17:03:48.762585Z"},"trusted":true},"execution_count":62,"outputs":[{"execution_count":62,"output_type":"execute_result","data":{"text/plain":"<tf.Tensor: shape=(14,), dtype=int32, numpy=\narray([ 1045,  1005,  2310,  2042,  3403,  2005,  1037, 17662, 12172,\n        2607,  2026,  2878,  2166,  1012], dtype=int32)>"},"metadata":{}}]},{"cell_type":"code","source":"# This line will fail.\n\nmodel(input_ids)","metadata":{"execution":{"iopub.status.busy":"2024-05-26T17:03:52.770854Z","iopub.execute_input":"2024-05-26T17:03:52.771241Z","iopub.status.idle":"2024-05-26T17:03:52.919320Z","shell.execute_reply.started":"2024-05-26T17:03:52.771212Z","shell.execute_reply":"2024-05-26T17:03:52.918235Z"},"trusted":true},"execution_count":64,"outputs":[{"execution_count":64,"output_type":"execute_result","data":{"text/plain":"TFSequenceClassifierOutput(loss=None, logits=<tf.Tensor: shape=(1, 2), dtype=float32, numpy=array([[-2.7276218,  2.8789387]], dtype=float32)>, hidden_states=None, attentions=None)"},"metadata":{}}]},{"cell_type":"code","source":"tokenized_inputs = tokenizer(sequence, return_tensors=\"tf\")\n\nprint(tokenized_inputs[\"input_ids\"])","metadata":{"execution":{"iopub.status.busy":"2024-05-26T17:03:53.822001Z","iopub.execute_input":"2024-05-26T17:03:53.822848Z","iopub.status.idle":"2024-05-26T17:03:53.829559Z","shell.execute_reply.started":"2024-05-26T17:03:53.822793Z","shell.execute_reply":"2024-05-26T17:03:53.828188Z"},"trusted":true},"execution_count":65,"outputs":[{"name":"stdout","text":"tf.Tensor(\n[[  101  1045  1005  2310  2042  3403  2005  1037 17662 12172  2607  2026\n   2878  2166  1012   102]], shape=(1, 16), dtype=int32)\n","output_type":"stream"}]},{"cell_type":"code","source":"import tensorflow as tf\nfrom transformers import AutoTokenizer, TFAutoModelForSequenceClassification\n\ncheckpoint = \"distilbert-base-uncased-finetuned-sst-2-english\"\ntokenizer = AutoTokenizer.from_pretrained(checkpoint)\nmodel = TFAutoModelForSequenceClassification.from_pretrained(checkpoint)\n\nsequence = \"I've been waiting for a HuggingFace course my whole life.\"\n\ntokens = tokenizer.tokenize(sequence)\nids = tokenizer.convert_tokens_to_ids(tokens)\n\ninput_ids = tf.constant([ids])\nprint(\"Input IDs:\", input_ids)\n\noutput = model(input_ids)\nprint(\"Logits:\", output.logits)","metadata":{"execution":{"iopub.status.busy":"2024-05-26T17:03:55.113441Z","iopub.execute_input":"2024-05-26T17:03:55.116189Z","iopub.status.idle":"2024-05-26T17:03:57.123666Z","shell.execute_reply.started":"2024-05-26T17:03:55.116138Z","shell.execute_reply":"2024-05-26T17:03:57.122593Z"},"trusted":true},"execution_count":66,"outputs":[{"name":"stderr","text":"All PyTorch model weights were used when initializing TFDistilBertForSequenceClassification.\n\nAll the weights of TFDistilBertForSequenceClassification were initialized from the PyTorch model.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertForSequenceClassification for predictions without further training.\n","output_type":"stream"},{"name":"stdout","text":"Input IDs: tf.Tensor(\n[[ 1045  1005  2310  2042  3403  2005  1037 17662 12172  2607  2026  2878\n   2166  1012]], shape=(1, 14), dtype=int32)\nLogits: tf.Tensor([[-2.7276218  2.8789387]], shape=(1, 2), dtype=float32)\n","output_type":"stream"}]},{"cell_type":"code","source":"batched_ids = [ids, ids]","metadata":{"execution":{"iopub.status.busy":"2024-05-26T17:03:57.125477Z","iopub.execute_input":"2024-05-26T17:03:57.125796Z","iopub.status.idle":"2024-05-26T17:03:57.132970Z","shell.execute_reply.started":"2024-05-26T17:03:57.125769Z","shell.execute_reply":"2024-05-26T17:03:57.131849Z"},"trusted":true},"execution_count":67,"outputs":[]},{"cell_type":"code","source":"input_ids = tf.constant(batched_ids)\nprint(\"Input IDs:\", input_ids)\n\noutput = model(input_ids)\nprint(\"Logits:\", output.logits)","metadata":{"execution":{"iopub.status.busy":"2024-05-26T17:03:57.788816Z","iopub.execute_input":"2024-05-26T17:03:57.789607Z","iopub.status.idle":"2024-05-26T17:03:57.977333Z","shell.execute_reply.started":"2024-05-26T17:03:57.789571Z","shell.execute_reply":"2024-05-26T17:03:57.976068Z"},"trusted":true},"execution_count":68,"outputs":[{"name":"stdout","text":"Input IDs: tf.Tensor(\n[[ 1045  1005  2310  2042  3403  2005  1037 17662 12172  2607  2026  2878\n   2166  1012]\n [ 1045  1005  2310  2042  3403  2005  1037 17662 12172  2607  2026  2878\n   2166  1012]], shape=(2, 14), dtype=int32)\nLogits: tf.Tensor(\n[[-2.7276225  2.8789396]\n [-2.727621   2.878938 ]], shape=(2, 2), dtype=float32)\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Putting it all together 🤗","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nfrom transformers import AutoTokenizer, TFAutoModelForSequenceClassification","metadata":{"execution":{"iopub.status.busy":"2024-05-26T17:12:23.410083Z","iopub.execute_input":"2024-05-26T17:12:23.410462Z","iopub.status.idle":"2024-05-26T17:12:23.415174Z","shell.execute_reply.started":"2024-05-26T17:12:23.410435Z","shell.execute_reply":"2024-05-26T17:12:23.413983Z"},"trusted":true},"execution_count":78,"outputs":[]},{"cell_type":"code","source":"sequence = \"Burkina Faso is a West African country divided into 45 provinces.\"\n\nsequences_multiples = [\n    \"Burkina Faso is a West African country divided into 45 provinces.\",\n    \"The official language is French, but other national languages such as Mooré, Peul, Dioula and Bissa are also spoken.\",\n]\n\ncheckpoint = \"distilbert-base-uncased-finetuned-sst-2-english\"","metadata":{"execution":{"iopub.status.busy":"2024-05-26T17:12:25.923702Z","iopub.execute_input":"2024-05-26T17:12:25.924113Z","iopub.status.idle":"2024-05-26T17:12:25.928951Z","shell.execute_reply.started":"2024-05-26T17:12:25.924075Z","shell.execute_reply":"2024-05-26T17:12:25.927783Z"},"trusted":true},"execution_count":79,"outputs":[]},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n\n# passer une seule séquence au modèle\nmodel_inputs = tokenizer(sequence)\nmodel_inputs","metadata":{"execution":{"iopub.status.busy":"2024-05-26T17:12:58.852115Z","iopub.execute_input":"2024-05-26T17:12:58.853005Z","iopub.status.idle":"2024-05-26T17:12:59.121563Z","shell.execute_reply.started":"2024-05-26T17:12:58.852963Z","shell.execute_reply":"2024-05-26T17:12:59.120453Z"},"trusted":true},"execution_count":83,"outputs":[{"execution_count":83,"output_type":"execute_result","data":{"text/plain":"{'input_ids': [101, 23089, 22773, 2003, 1037, 2225, 3060, 2406, 4055, 2046, 3429, 6941, 1012, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"},"metadata":{}}]},{"cell_type":"code","source":"# passer plusieurs séquences au modèle\nmodel_inputs = tokenizer(sequences_multiples)\nmodel_inputs","metadata":{"execution":{"iopub.status.busy":"2024-05-26T17:13:10.251635Z","iopub.execute_input":"2024-05-26T17:13:10.252049Z","iopub.status.idle":"2024-05-26T17:13:10.260384Z","shell.execute_reply.started":"2024-05-26T17:13:10.252010Z","shell.execute_reply":"2024-05-26T17:13:10.259146Z"},"trusted":true},"execution_count":84,"outputs":[{"execution_count":84,"output_type":"execute_result","data":{"text/plain":"{'input_ids': [[101, 23089, 22773, 2003, 1037, 2225, 3060, 2406, 4055, 2046, 3429, 6941, 1012, 102], [101, 1996, 2880, 2653, 2003, 2413, 1010, 2021, 2060, 2120, 4155, 2107, 2004, 5405, 1010, 21877, 5313, 1010, 4487, 7140, 2721, 1998, 20377, 3736, 2024, 2036, 5287, 1012, 102]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}"},"metadata":{}}]},{"cell_type":"code","source":"# Les séquences seront remplies jusqu'à la longueur maximale de la séquence.\nmodel_inputs = tokenizer(sequences, padding=\"longest\")\n\n# Remplit les séquences jusqu'à la longueur maximale du modèle\n# (512 pour BERT ou DistilBERT)\nmodel_inputs = tokenizer(sequences, padding=\"max_length\")\n\n# Remplit les séquences jusqu'à la longueur maximale spécifiée.\nmodel_inputs = tokenizer(sequences, padding=\"max_length\", max_length=8)","metadata":{"execution":{"iopub.status.busy":"2024-05-26T17:15:32.200035Z","iopub.execute_input":"2024-05-26T17:15:32.200502Z","iopub.status.idle":"2024-05-26T17:15:32.207634Z","shell.execute_reply.started":"2024-05-26T17:15:32.200475Z","shell.execute_reply":"2024-05-26T17:15:32.206526Z"},"trusted":true},"execution_count":85,"outputs":[]},{"cell_type":"markdown","source":"## Les Tokens spéciaux","metadata":{}},{"cell_type":"code","source":"model_inputs = tokenizer(sequence)\nprint(model_inputs[\"input_ids\"])\n\ntokens = tokenizer.tokenize(sequence)\nids = tokenizer.convert_tokens_to_ids(tokens)\nprint(ids)","metadata":{"execution":{"iopub.status.busy":"2024-05-26T17:15:57.836271Z","iopub.execute_input":"2024-05-26T17:15:57.836668Z","iopub.status.idle":"2024-05-26T17:15:57.844466Z","shell.execute_reply.started":"2024-05-26T17:15:57.836638Z","shell.execute_reply":"2024-05-26T17:15:57.842986Z"},"trusted":true},"execution_count":86,"outputs":[{"name":"stdout","text":"[101, 23089, 22773, 2003, 1037, 2225, 3060, 2406, 4055, 2046, 3429, 6941, 1012, 102]\n[23089, 22773, 2003, 1037, 2225, 3060, 2406, 4055, 2046, 3429, 6941, 1012]\n","output_type":"stream"}]},{"cell_type":"code","source":"# en résumé \n\nimport tensorflow as tf\nfrom transformers import AutoTokenizer, TFAutoModelForSequenceClassification\n\ncheckpoint = \"distilbert-base-uncased-finetuned-sst-2-english\"\ntokenizer = AutoTokenizer.from_pretrained(checkpoint)\nmodel = TFAutoModelForSequenceClassification.from_pretrained(checkpoint)\n\nsequence = \"I've been waiting for a HuggingFace course my whole life.\"\n\ntokens = tokenizer.tokenize(sequence)\nids = tokenizer.convert_tokens_to_ids(tokens)\ninput_ids = tf.constant(ids)","metadata":{},"execution_count":null,"outputs":[{"name":"stderr","output_type":"stream","text":"2024-04-05 22:52:47.197617: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n\n2024-04-05 22:52:47.197888: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n\n2024-04-05 22:52:47.370569: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"20f1fbb8b547481eace1c33468ebe58e","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"15f1b21569fb44dfa1b17fcda892a10c","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/629 [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9e7a65a9237e4103ba485399ffa5af5a","version_major":2,"version_minor":0},"text/plain":["vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b050498913334ea38c90ad4bcc80d8e9","version_major":2,"version_minor":0},"text/plain":["model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"]},"metadata":{}},{"name":"stderr","output_type":"stream","text":"All PyTorch model weights were used when initializing TFDistilBertForSequenceClassification.\n\n\n\nAll the weights of TFDistilBertForSequenceClassification were initialized from the PyTorch model.\n\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertForSequenceClassification for predictions without further training.\n"}]}]}